{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:XLA_CPU:0', '/device:XLA_GPU:0', '/device:XLA_GPU:1', '/device:GPU:0', '/device:GPU:1']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2b33e0c992cb>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "#tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from Capsule_net_modified import get_model\n",
    "from utils import Metrics\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/data/cross_validation'\n",
    "MODEL_DIR = '/tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size'\n",
    "FOLD = 0\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "TRAINABLE_BASE_LAYERS = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Model is called : {model_name_capsule}\n",
      "selected fold: {FOLD}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'pocus_fold_{0}'\n",
    "plot_path = 'pocus_fold_{0}'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print('Loading images...')\n",
    "imagePaths = list(paths.list_images(DATA_DIR))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "print('Model is called : {model_name_capsule}')\n",
    "print('selected fold: {FOLD}')\n",
    "\n",
    "train_labels, test_labels = [], []\n",
    "train_data, test_data = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training samples: len(train_labels) \n",
      "Number of testing samples: len(test_labels)\n"
     ]
    }
   ],
   "source": [
    "for imagePath in imagePaths:\n",
    "    path_parts = imagePath.split(os.path.sep)\n",
    "    # extract the split\n",
    "    train_test = path_parts[-3][-1]\n",
    "    # extract the class label from the filename\n",
    "    label = path_parts[-2]\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    if train_test == str(FOLD):\n",
    "        test_labels.append(label)\n",
    "        test_data.append(image)\n",
    "    else:\n",
    "        train_labels.append(label)\n",
    "        train_data.append(image)\n",
    "\n",
    "# Prepare data for model\n",
    "print(\n",
    "    '\\nNumber of training samples: len(train_labels) \\n'\n",
    "    'Number of testing samples: len(test_labels)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(set(train_labels)) == len(set(test_labels)), (\n",
    "    'Something went wrong. Some classes are only in train or test data.'\n",
    ")  # yapf: disable\n",
    "\n",
    "# convert the data and labels to NumPy arrays while scaling the pixel\n",
    "# intensities to the range [0, 255]\n",
    "train_data = np.array(train_data) / 255.0\n",
    "test_data = np.array(test_data) / 255.0\n",
    "train_labels_text = np.array(train_labels)\n",
    "test_labels_text = np.array(test_labels)\n",
    "\n",
    "num_classes = len(set(train_labels))\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(train_labels_text)\n",
    "\n",
    "train_labels = lb.transform(train_labels_text)\n",
    "test_labels = lb.transform(test_labels_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['covid', 'covid', 'covid', ..., 'regular', 'regular', 'regular'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf; \n",
    "#print(tf.__version__)\n",
    "#!pip install q keras==2.1.2\n",
    "#! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mappings are: ['covid' 'pneumonia' 'regular']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if num_classes == 2:\n",
    "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "    test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "trainX = train_data\n",
    "trainY = train_labels\n",
    "testX = test_data\n",
    "testY = test_labels\n",
    "print('Class mappings are:', lb.classes_)\n",
    "\n",
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Load the VGG16 network\n",
    "model = get_model(\n",
    "    input_size=(IMG_WIDTH, IMG_HEIGHT, 3), num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Compiling model...\n",
      "Model has {model.count_params()} parameters\n",
      "Model summary {model.summary()}\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "capsule (Capsule)            (None, 32, 8)             32768     \n",
      "_________________________________________________________________\n",
      "capsule_1 (Capsule)          (None, 32, 8)             2048      \n",
      "_________________________________________________________________\n",
      "capsule_2 (Capsule)          (None, 3, 16)             384       \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 295,616\n",
      "Trainable params: 295,488\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of layers in model head (fresh weights), this is fixed in get_model.\n",
    "#num_head_layers = 7\n",
    "# Freeze all VGG layers apart from the last layers (TRAINABLE_BASE_LAYERS)\n",
    "#num_layers = len(model.layers)\n",
    "#for ind, layer in enumerate(model.layers):\n",
    "#    if ind < num_layers - num_head_layers - TRAINABLE_BASE_LAYERS:\n",
    "#        layer.trainable = False\n",
    "\n",
    "# Define callbacks\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "mcp_save = ModelCheckpoint(\n",
    "    os.path.join(MODEL_DIR, 'fold_' + str(FOLD) + '_epoch_{epoch:02d}'),\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "reduce_lr_loss = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    epsilon=1e-4,\n",
    "    mode='min'\n",
    ")\n",
    "# To show balanced accuracy\n",
    "metrics = Metrics((testX, testY), model)\n",
    "\n",
    "# compile model\n",
    "print('Compiling model...')\n",
    "#opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "opt = Adam(lr=LR, decay = 0)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('Model has {model.count_params()} parameters')\n",
    "print('Model summary {model.summary()}')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training model...\n",
      "WARNING:tensorflow:From <ipython-input-13-33c78cffd409>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 115 steps, validate on 428 samples\n",
      "Epoch 1/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.9700 - accuracy: 0.5981\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55769, saving model to /tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size/fold_0_epoch_01\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size/fold_0_epoch_01/assets\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "115/115 [==============================] - 38s 326ms/step - loss: 0.9699 - accuracy: 0.5984 - val_loss: 0.9486 - val_accuracy: 0.5577\n",
      "Epoch 2/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.9041 - accuracy: 0.6114\n",
      "Epoch 00002: val_accuracy did not improve from 0.55769\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "115/115 [==============================] - 31s 266ms/step - loss: 0.9060 - accuracy: 0.6109 - val_loss: 0.9230 - val_accuracy: 0.5577\n",
      "Epoch 3/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.8539 - accuracy: 0.6301\n",
      "Epoch 00003: val_accuracy did not improve from 0.55769\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "115/115 [==============================] - 32s 275ms/step - loss: 0.8537 - accuracy: 0.6306 - val_loss: 0.9872 - val_accuracy: 0.5577\n",
      "Epoch 4/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.8056 - accuracy: 0.6494\n",
      "Epoch 00004: val_accuracy did not improve from 0.55769\n",
      "Balanced accuracy is: {'val_balanced': 0.1867816091954023}\n",
      "115/115 [==============================] - 30s 263ms/step - loss: 0.8044 - accuracy: 0.6514 - val_loss: 1.0696 - val_accuracy: 0.2139\n",
      "Epoch 5/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.7659 - accuracy: 0.6781\n",
      "Epoch 00005: val_accuracy did not improve from 0.55769\n",
      "Balanced accuracy is: {'val_balanced': 0.3704022988505747}\n",
      "115/115 [==============================] - 31s 266ms/step - loss: 0.7653 - accuracy: 0.6781 - val_loss: 0.9170 - val_accuracy: 0.5192\n",
      "Epoch 6/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.7420\n",
      "Epoch 00006: val_accuracy improved from 0.55769 to 0.56971, saving model to /tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size/fold_0_epoch_06\n",
      "INFO:tensorflow:Assets written to: /tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size/fold_0_epoch_06/assets\n",
      "Balanced accuracy is: {'val_balanced': 0.48017241379310355}\n",
      "115/115 [==============================] - 33s 285ms/step - loss: 0.6895 - accuracy: 0.7421 - val_loss: 0.8839 - val_accuracy: 0.5697\n",
      "Epoch 7/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.5664 - accuracy: 0.8394\n",
      "Epoch 00007: val_accuracy did not improve from 0.56971\n",
      "Balanced accuracy is: {'val_balanced': 0.41379310344827586}\n",
      "115/115 [==============================] - 31s 271ms/step - loss: 0.5644 - accuracy: 0.8399 - val_loss: 0.9147 - val_accuracy: 0.5240\n",
      "Epoch 8/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.8820\n",
      "Epoch 00008: val_accuracy did not improve from 0.56971\n",
      "Balanced accuracy is: {'val_balanced': 0.4252873563218391}\n",
      "115/115 [==============================] - 31s 268ms/step - loss: 0.4604 - accuracy: 0.8825 - val_loss: 0.9742 - val_accuracy: 0.5673\n",
      "Epoch 9/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.9201\n",
      "Epoch 00009: val_accuracy did not improve from 0.56971\n",
      "Balanced accuracy is: {'val_balanced': 0.39367816091954017}\n",
      "115/115 [==============================] - 30s 261ms/step - loss: 0.3717 - accuracy: 0.9191 - val_loss: 0.9877 - val_accuracy: 0.5096\n",
      "Epoch 10/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.3341 - accuracy: 0.9228\n",
      "Epoch 00010: val_accuracy improved from 0.56971 to 0.60817, saving model to /tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size/fold_0_epoch_10\n",
      "INFO:tensorflow:Assets written to: /tf/Modified/covid19_pocus_ultrasound_master/covid19_pocus_ultrasound_master/models/Model_Size/fold_0_epoch_10/assets\n",
      "Balanced accuracy is: {'val_balanced': 0.5086206896551725}\n",
      "115/115 [==============================] - 33s 288ms/step - loss: 0.3329 - accuracy: 0.9235 - val_loss: 1.1061 - val_accuracy: 0.6082\n",
      "Epoch 11/50\n",
      "114/115 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.9338\n",
      "Epoch 00011: val_accuracy did not improve from 0.60817\n",
      "Balanced accuracy is: {'val_balanced': 0.4051724137931035}\n",
      "115/115 [==============================] - 30s 263ms/step - loss: 0.2824 - accuracy: 0.9339 - val_loss: 1.1082 - val_accuracy: 0.5337\n",
      "Epoch 12/50\n",
      " 60/115 [==============>...............] - ETA: 13s - loss: 0.2468 - accuracy: 0.9417WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "Balanced accuracy is: {'val_balanced': 0.4252873563218391}\n",
      " 60/115 [==============>...............] - ETA: 14s - loss: 0.2468 - accuracy: 0.9417"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-33c78cffd409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# train the head of the network\n",
    "print('Starting training model...')\n",
    "H = model.fit_generator(\n",
    "    trainAug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[earlyStopping, mcp_save, reduce_lr_loss, metrics]\n",
    ")\n",
    "\n",
    "# make predictions on the testing set\n",
    "print('Evaluating network...')\n",
    "predIdxs = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "print('classification report sklearn:')\n",
    "print(\n",
    "    classification_report(\n",
    "        testY.argmax(axis=1), predIdxs, target_names=lb.classes_\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('confusion matrix:')\n",
    "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
    "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# serialize the model to disk\n",
    "#print('Saving COVID-19 detector model on {model_name} data...')\n",
    "#model.save(os.path.join(MODEL_DIR, model_name), save_format='h5')\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, N), H.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, N), H.history['accuracy'], label='train_acc')\n",
    "plt.plot(np.arange(0, N), H.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Training Loss and Accuracy on COVID-19 Dataset')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='lower left')\n",
    "plt.savefig(os.path.join(MODEL_DIR, plot_path))\n",
    "\n",
    "print('Done, shuttting down!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
